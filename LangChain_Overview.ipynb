{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75a6bcee-b821-4b0e-9712-ced3f362bdb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LangChain Overview\n",
    "\n",
    "All code comes from [LangChain docs](langchain.readthedocs.io).\n",
    "\n",
    "2023-07-01 rhm2k - Minor modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc576310-3ca1-48dc-b188-16377585fbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install langchain openai cohere huggingface_hub ipywidgets chromadb google-search-results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-07-01 RHM additional dependencies\n",
    "%pip install pylance tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469cafb-adab-48f7-9645-3447a2aa1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# -----------------------------------------\n",
    "# 2023-07-01 use .env file to prevent API keys from being included in code commits\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import textwrap\n",
    "# -----------------------------------------\n",
    "\n",
    "import langchain\n",
    "from langchain.llms import OpenAI, Cohere, HuggingFaceHub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1140620-f6c2-47a2-b4ab-97bcca405c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# 2023-07-01 Using .env file\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "SERPAPI_API_KEY = os.environ[\"SERPAPI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485e97f-81cd-441e-a574-eb08bdbb6d03",
   "metadata": {},
   "source": [
    "# LLMs\n",
    "\n",
    "Integration with many LLM providers\n",
    "- OpenAI\n",
    "- Cohere\n",
    "- AI21\n",
    "- Huggingface Hub\n",
    "- Azure OpenAI\n",
    "- Manifest\n",
    "- Goose AI\n",
    "- Writer\n",
    "- Banana\n",
    "- Modal\n",
    "- StochasticAI\n",
    "- Cerebrium\n",
    "- Petals\n",
    "- Forefront AI\n",
    "- PromptLayer OpenAI\n",
    "- Anthropic\n",
    "- DeepInfra\n",
    "- Self-Hosted Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba64897-6732-4441-80ed-36671e4b02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa6934-44e3-4daa-b1ac-bcf61e6e2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = OpenAI(model_name='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b5e43-1020-4a42-80bb-30d3b30bcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere = Cohere(model='command-xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0684523-0a0b-4858-b44b-f5c04ecdaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flan = HuggingFaceHub(repo_id=\"google/flan-t5-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec92bad-7ea6-4131-a342-5e1a6f48479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"How to be happy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76574d9-8815-4af3-b444-eb256a5fe0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt([HumanMessage(content=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e09a2b-7b91-4edc-b6e1-8a0428098345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e987a19-bfdf-4d60-849c-d8168b79a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cohere(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612932a-974e-4a4a-abce-7ae91dd95a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-07-01 Run-away failure\n",
    "# print(flan(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783cb2d-d3ca-426b-94cf-13e1eb966486",
   "metadata": {},
   "source": [
    "# Question Answering with external document\n",
    "\n",
    "There are a lot of document loaders:\n",
    "File Loader, Directory Loader, Notion, ReadTheDocs, HTML, PDF, PowerPoint, Email, GoogleDrive, Obsidian, Roam, EverNote, YouTube, Hacker News, GitBook, S3 File, S3 Directory, GCS File, GCS Directory, Web Base, IMSDb, AZLyrics, College Confidential, Gutenberg, Airbyte Json, CoNLL-U, iFixit, Notebook, Copypaste, CSV, Facebook Chat, Image, Markdown, SRT, Telegram, URL, Word Document, Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf6ce2-2411-4167-860b-e3c2214b5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('state_of_the_union.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8ce64-23be-4c8d-b78e-4444588b0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b1fd9-c8ae-4072-b40d-bff6eabac0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "# index.query(query)\n",
    "# -----------------------------------------\n",
    "# 2023-07-01 RHM \n",
    "# set up for text wrap at 80 chars\n",
    "import textwrap\n",
    "long_string = index.query(query)\n",
    "\n",
    "wrapped_string = textwrap.fill(long_string, width=80)\n",
    "\n",
    "print(wrapped_string)\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513e651-7205-4457-a282-ffcd20ca513b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Keep memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393cd9d-3dd0-4469-abf1-dc6d8a029929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory, CombinedMemory, ConversationSummaryMemory\n",
    "\n",
    "\n",
    "conv_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history_lines\",\n",
    "    input_key=\"input\",\n",
    "    k=1\n",
    ")\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(llm=OpenAI(), input_key=\"input\")\n",
    "# Combined\n",
    "memory = CombinedMemory(memories=[conv_memory, summary_memory])\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Summary of conversation:\n",
    "{history}\n",
    "Current conversation:\n",
    "{chat_history_lines}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\", \"chat_history_lines\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=memory,\n",
    "    prompt=PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ef99d-51a0-41e5-aa58-35517e097a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b03643-df85-4f7e-9580-910c77330eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Can you tell me a joke?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c247979-2e7d-4953-a901-83eceeceecb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Can you tell me a similar joke?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14d389-fc9d-4d01-85f7-5408073395f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973720b-4edc-4b39-92f4-98b9e4f3c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=\"What is a good name for a company that makes {product}?\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "print(chain.run(\"funny hats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b35a4-8f56-4a2b-9c71-de91d67253b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Write a catchphrase for the following company: {company_name}\",\n",
    ")\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad82c8-5a1d-42e5-ad65-9fd7b5987976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "catchphrase = overall_chain.run(\"funny hats\")\n",
    "print(catchphrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203d1dd-607e-425e-a7ea-70e755e0084f",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01df7c-34bd-44fe-83d5-5f3b8d3c2393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=gpt3)\n",
    "agent = initialize_agent(tools, llm=gpt3, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efb8e9-b59e-4548-902c-6cdfe9825a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Who is Larry Ellison's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c90a4-88a1-401f-8ecd-6c6fa5184b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\", \"python_repl\"], llm=gpt3)\n",
    "agent = initialize_agent(tools, llm=gpt3, agent=\"zero-shot-react-description\", verbose=True)\n",
    "agent.run(\"Who is Larry Ellison's girlfriend? What is her current age raised to the 0.49 power?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ploomber1",
   "language": "python",
   "name": "ploomber1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
